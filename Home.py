import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve
from sklearn.preprocessing import LabelEncoder, StandardScaler
import warnings
warnings.filterwarnings('ignore')

# Page Configuration
st.set_page_config(
    page_title="Kalp SaÄŸlÄ±ÄŸÄ± Risk Analizi",
    page_icon="â¤ï¸",
    layout="wide"
)

# --- CUSTOM STYLING ---
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .risk-high {
        color: #d32f2f;
        font-weight: bold;
    }
    .risk-low {
        color: #388e3c;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# --- 1. DATA LOADING AND MODEL TRAINING ---
@st.cache_resource
def load_and_train_optimized_model():
    """
    Load data and train optimized ensemble model with:
    - Hyperparameter tuning
    - Class weight balancing
    - Multiple model approaches
    - Cross-validation
    """
    try:
        df = pd.read_csv('data/heart_disease_uci.csv')
    except FileNotFoundError:
        st.error("Dataset not found. Please ensure 'heart_disease_uci.csv' is in the correct location.")
        return None, None, None, None, None

    # Data Cleaning
    df = df.drop(['id', 'dataset'], axis=1)
    df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)
    df = df.drop('num', axis=1)

    # Handle Missing Values
    for col in df.columns:
        if df[col].dtype == 'object':
            if df[col].isnull().sum() > 0:
                df[col] = df[col].fillna(df[col].mode()[0])
        else:
            if df[col].isnull().sum() > 0:
                df[col] = df[col].fillna(df[col].median())

    # Encode Categorical Variables
    encoders = {}
    for col in df.select_dtypes(include=['object']).columns:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
        encoders[col] = le

    # Train-Test Split
    X = df.drop('target', axis=1)
    y = df['target']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # Scale features for LogisticRegression
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # --- OPTIMIZED MODELS ---
    
    # 1. Tuned Random Forest with class weights
    rf_model = RandomForestClassifier(
        n_estimators=200,
        max_depth=10,
        min_samples_split=2,
        min_samples_leaf=2,
        max_features='sqrt',
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )
    rf_model.fit(X_train, y_train)

    # 2. Tuned Gradient Boosting
    gb_model = GradientBoostingClassifier(
        n_estimators=200,
        learning_rate=0.01,
        max_depth=3,
        min_samples_split=5,
        random_state=42,
        validation_fraction=0.1,
        n_iter_no_change=10
    )
    gb_model.fit(X_train, y_train)

    # 3. Logistic Regression
    lr_model = LogisticRegression(
        max_iter=1000,
        class_weight='balanced',
        random_state=42
    )
    lr_model.fit(X_train_scaled, y_train)

    # 4. Voting Ensemble
    ensemble_model = VotingClassifier(
        estimators=[
            ('rf', rf_model),
            ('gb', gb_model),
            ('lr', lr_model)
        ],
        voting='soft'
    )
    ensemble_model.fit(X_train, y_train)

    # Evaluation on Test Set
    y_pred_ensemble = ensemble_model.predict(X_test)
    y_pred_proba_ensemble = ensemble_model.predict_proba(X_test)[:, 1]
    
    accuracy = accuracy_score(y_test, y_pred_ensemble)
    roc_auc = roc_auc_score(y_test, y_pred_proba_ensemble)

    # Feature Importance from Random Forest
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=False)

    # Cross-validation Score
    cv_scores = cross_val_score(ensemble_model, X, y, cv=5, scoring='roc_auc')
    
    model_info = {
        'accuracy': accuracy,
        'roc_auc': roc_auc,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'test_set_size': len(y_test),
        'positive_class_pct': (y == 1).sum() / len(y) * 100
    }

    return ensemble_model, encoders, df, feature_importance, model_info

# Load models
ensemble_model, encoders, df_clean, feature_importance, model_info = load_and_train_optimized_model()

if ensemble_model is None:
    st.stop()

# --- 2. INTERFACE DESIGN ---

st.title("â¤ï¸ Yapay Zeka Destekli Kalp HastalÄ±ÄŸÄ± Risk Analizi")
st.markdown("""
Bu uygulama, kalp hastalÄ±ÄŸÄ± riskini tahmin etmek iÃ§in optimize edilmiÅŸ topluluk makine Ã¶ÄŸrenimi modeli kullanmaktadÄ±r.
**LÃ¼tfen hasta bilgilerini aÅŸaÄŸÄ±daki formlara giriniz.**

**Model PerformansÄ±:**
- Test DoÄŸruluÄŸu: **{:.2%}**
- ROC-AUC Skoru: **{:.4f}**
- Ã‡apraz DoÄŸrulama AUC: **{:.4f} Â± {:.4f}**
""".format(
    model_info['accuracy'],
    model_info['roc_auc'],
    model_info['cv_mean'],
    model_info['cv_std']
))

st.sidebar.header("Hasta Bilgileri GiriÅŸi")
st.sidebar.markdown("LÃ¼tfen hasta test sonuÃ§larÄ±nÄ± giriniz.")

# Expected ranges for validation
FEATURE_RANGES = {
    'age': (20, 80),
    'trestbps': (90, 200),
    'chol': (100, 600),
    'thalach': (60, 220),
    'oldpeak': (0.0, 6.0),
    'ca': (0, 3)
}

def user_input_features():
    """KullanÄ±cÄ± giriÅŸini doÄŸrulama ile topla"""
    with st.expander("ğŸ“‹ Demografik Bilgiler", expanded=True):
        age = st.slider('YaÅŸ', 20, 80, 50, help="HastanÄ±n yaÅŸÄ± (yÄ±l cinsinden). YaÅŸ arttÄ±kÃ§a kalp hastalÄ±ÄŸÄ± riski genelde artar.")
        
        sex_disp = st.selectbox('Cinsiyet', ('Erkek', 'KadÄ±n'), help="Erkeklerde kalp hastalÄ±ÄŸÄ± riski genelde daha yÃ¼ksektir.")
        sex = 'Male' if sex_disp == 'Erkek' else 'Female'

    with st.expander("ğŸ©º Klinik Bulgular", expanded=True):
        cp_map = {
            'Tipik Anjina': 'typical angina',
            'Atipik Anjina': 'atypical angina',
            'Anjinal Olmayan AÄŸrÄ±': 'non-anginal',
            'Asemptomatik': 'asymptomatic'
        }
        cp_disp = st.selectbox('GÃ¶ÄŸÃ¼s AÄŸrÄ±sÄ± Tipi', list(cp_map.keys()), 
                               help="GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ±nÄ±n tÃ¼rÃ¼ kalp hastalÄ±ÄŸÄ± iÃ§in Ã¶nemli bir belirteÃ§tir. Tipik anjina en riskli olanÄ±dÄ±r.")
        cp = cp_map[cp_disp]
        
        trestbps = st.number_input(
            'Ä°stirahat Kan BasÄ±ncÄ± (mm Hg)', 90, 200, 120,
            help="Hastaneye baÅŸvuru sÄ±rasÄ±ndaki dinlenme tansiyonu. Normal: 120/80 mm Hg. YÃ¼ksek tansiyon risk faktÃ¶rÃ¼dÃ¼r."
        )
        
        chol = st.number_input(
            'Serum Kolesterolu (mg/dl)', 100, 600, 200,
            help="Kandaki toplam kolesterol. Ä°deal: <200 mg/dl. YÃ¼ksek kolesterol damar tÄ±kanÄ±klÄ±ÄŸÄ±na yol aÃ§abilir."
        )
        
        fbs_disp = st.radio('AÃ§lÄ±k Kan Åekeri > 120 mg/dl?', ('HayÄ±r', 'Evet'),
                           help="YÃ¼ksek aÃ§lÄ±k kan ÅŸekeri diyabet ve kalp hastalÄ±ÄŸÄ± riski gÃ¶stergesidir.")
        fbs = True if fbs_disp == 'Evet' else False

    with st.expander("ğŸ“Š Test SonuÃ§larÄ±", expanded=True):
        restecg_map = {
            'Normal': 'normal',
            'ST-T Dalga AnormalliÄŸi': 'st-t abnormality',
            'Sol VentrikÃ¼l Hipertrofisi': 'lv hypertrophy'
        }
        restecg_disp = st.selectbox('Ä°stirahat EKG Sonucu', list(restecg_map.keys()),
                                   help="Dinlenme halindeki EKG sonucu. Anormallikler kalp sorunu iÅŸareti olabilir.")
        restecg = restecg_map[restecg_disp]
        
        thalach = st.slider(
            'Maksimum Kalp AtÄ±ÅŸ HÄ±zÄ±', 60, 220, 150,
            help="Efor testi sÄ±rasÄ±nda ulaÅŸÄ±lan en yÃ¼ksek nabÄ±z. DÃ¼ÅŸÃ¼k deÄŸerler kalp sorunu gÃ¶sterebilir."
        )
        
        exang_disp = st.radio('Egzersize BaÄŸlÄ± Anjina?', ('HayÄ±r', 'Evet'),
                             help="Efor sÄ±rasÄ±nda gÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± oluÅŸuyor mu? Evet cevabÄ± yÃ¼ksek risk gÃ¶stergesidir.")
        exang = True if exang_disp == 'Evet' else False
        
        oldpeak = st.slider(
            'ST Depresyonu (Oldpeak)', 0.0, 6.0, 1.0, 0.1,
            help="Egzersiz sÄ±rasÄ±nda EKG'de oluÅŸan ST segment Ã§Ã¶kmesi. YÃ¼ksek deÄŸerler iskemi belirtisidir."
        )
        
        slope_map = {
            'YukarÄ± EÄŸimli': 'upsloping',
            'DÃ¼z': 'flat',
            'AÅŸaÄŸÄ± EÄŸimli': 'downsloping'
        }
        slope_disp = st.selectbox('ST Segment EÄŸimi', list(slope_map.keys()),
                                 help="Efor sÄ±rasÄ±ndaki ST segment eÄŸimi. YukarÄ± eÄŸimli genelde iyidir, dÃ¼z/aÅŸaÄŸÄ± eÄŸimli risklidir.")
        slope = slope_map[slope_disp]
        
        ca = st.slider(
            'Ana Damar SayÄ±sÄ± (0-3)', 0, 3, 0,
            help="Floroskopi ile gÃ¶rÃ¼ntÃ¼lenen tÄ±kalÄ±/daralmÄ±ÅŸ ana damar sayÄ±sÄ±. SayÄ± arttÄ±kÃ§a risk artar."
        )
        
        thal_map = {
            'Normal': 'normal',
            'Sabit Kusur': 'fixed defect',
            'Tersine Ã‡evrilebilir Kusur': 'reversable defect'
        }
        thal_disp = st.selectbox('Talasemi Durumu', list(thal_map.keys()),
                                help="Kalbe giden kan akÄ±ÅŸÄ± durumu. Kusurlar iskemi veya kalÄ±cÄ± hasar gÃ¶sterebilir.")
        thal = thal_map[thal_disp]

    data = {
        'age': age, 'sex': sex, 'cp': cp, 'trestbps': trestbps,
        'chol': chol, 'fbs': fbs, 'restecg': restecg,
        'thalch': thalach, 'exang': exang, 'oldpeak': oldpeak,
        'slope': slope, 'ca': ca, 'thal': thal
    }
    return pd.DataFrame(data, index=[0])

input_df = user_input_features()

# --- 3. PREDICTION AND ANALYSIS ---

def encode_input(input_df, encoders):
    """Encode categorical variables safely"""
    input_df_encoded = input_df.copy()
    for col, encoder in encoders.items():
        if col in input_df_encoded.columns:
            try:
                input_df_encoded[col] = encoder.transform(input_df_encoded[col])
            except ValueError:
                # Handle unknown categories
                input_df_encoded[col] = 0
    return input_df_encoded

col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("Girilen Hasta Bilgileri")
    st.write(input_df)
    
    if st.button('ğŸ” Risk Analizi Yap', use_container_width=True):
        input_df_encoded = encode_input(input_df, encoders)
        
        # Get predictions from ensemble
        prediction = ensemble_model.predict(input_df_encoded)[0]
        prediction_proba = ensemble_model.predict_proba(input_df_encoded)[0]
        
        risk_probability = prediction_proba[1]
        confidence = max(prediction_proba) * 100
        
        st.divider()
        st.subheader("Analiz SonuÃ§larÄ±")
        
        # Risk DeÄŸerlendirmesi
        col_risk1, col_risk2, col_risk3 = st.columns(3)
        
        with col_risk1:
            st.metric("Risk OlasÄ±lÄ±ÄŸÄ±", f"{risk_probability*100:.1f}%")
        
        with col_risk2:
            st.metric("Model GÃ¼veni", f"{confidence:.1f}%")
        
        with col_risk3:
            if risk_probability > 0.5:
                st.metric("Risk Seviyesi", "ğŸ”´ YÃœKSEK")
            else:
                st.metric("Risk Seviyesi", "ğŸŸ¢ DÃœÅÃœK")
        
        # Detailed Assessment
        st.markdown("---")
        
        if risk_probability > 0.7:
            st.error("âš ï¸ **YÃœKSEK RÄ°SK TESPÄ°T EDÄ°LDÄ°**")
            st.write(f"""
            Model, **%{risk_probability*100:.1f}** kalp hastalÄ±ÄŸÄ± olasÄ±lÄ±ÄŸÄ± gÃ¶stermektedir.
            
            **Ã–neriler:**
            - Derhal bir kardiyolog ile gÃ¶rÃ¼ÅŸÃ¼nÃ¼z
            - KapsamlÄ± kalp testleri yaptÄ±rÄ±nÄ±z (EKG, efor testi, anjiyografi)
            - Risk faktÃ¶rlerini gÃ¶zden geÃ§irin ve yÃ¶netin (tansiyon, kolesterol, egzersiz)
            - ReÃ§ete edilen ilaÃ§larÄ± dÃ¼zenli kullanÄ±nÄ±z
            - SaÄŸlÄ±klÄ± beslenme ve yaÅŸam tarzÄ± deÄŸiÅŸiklikleri yapÄ±nÄ±z
            """)
        elif risk_probability > 0.5:
            st.warning("âš ï¸ **ORTA DÃœZEY RÄ°SK**")
            st.write(f"""
            Model, **%{risk_probability*100:.1f}** kalp hastalÄ±ÄŸÄ± olasÄ±lÄ±ÄŸÄ± gÃ¶stermektedir.
            
            **Ã–neriler:**
            - Bir kardiyolog ile randevu alÄ±nÄ±z
            - KapsamlÄ± kalp saÄŸlÄ±ÄŸÄ± deÄŸerlendirmesi yaptÄ±rÄ±nÄ±z
            - YaÅŸamsal belirtileri dÃ¼zenli olarak kontrol ediniz
            - YaÅŸam tarzÄ± deÄŸiÅŸiklikleri uygulayÄ±nÄ±z
            - DÃ¼zenli egzersiz ve saÄŸlÄ±klÄ± beslenme programÄ± baÅŸlatÄ±nÄ±z
            """)
        else:
            st.success("âœ… **DÃœÅÃœK RÄ°SK**")
            st.write(f"""
            Model, **%{risk_probability*100:.1f}** kalp hastalÄ±ÄŸÄ± olasÄ±lÄ±ÄŸÄ± gÃ¶stermektedir.
            
            **Ã–neriler:**
            - DÃ¼zenli saÄŸlÄ±k kontrollerine devam ediniz
            - SaÄŸlÄ±klÄ± yaÅŸam tarzÄ±nÄ± sÃ¼rdÃ¼rÃ¼nÃ¼z
            - Risk faktÃ¶rlerini periyodik olarak takip ediniz
            - Kolesterol ve kan basÄ±ncÄ±nÄ± kontrol altÄ±nda tutunuz
            - Dengeli beslenme ve dÃ¼zenli egzersize Ã¶zen gÃ¶steriniz
            """)

        # KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz
        st.subheader("KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz")
        
        # Hasta gruplarÄ± ile karÅŸÄ±laÅŸtÄ±r
        sick_avg = df_clean[df_clean['target'] == 1].mean(numeric_only=True)
        healthy_avg = df_clean[df_clean['target'] == 0].mean(numeric_only=True)
        
        metrics_compare = ['chol', 'thalch', 'trestbps']
        labels_compare = ['Kolesterol', 'Maks Kalp HÄ±zÄ±', 'Kan BasÄ±ncÄ±']
        
        fig, ax = plt.subplots(figsize=(11, 5))
        x = np.arange(len(metrics_compare))
        width = 0.25
        
        user_vals = [input_df['chol'][0], input_df['thalch'][0], input_df['trestbps'][0]]
        sick_vals = [sick_avg['chol'], sick_avg['thalch'], sick_avg['trestbps']]
        healthy_vals = [healthy_avg['chol'], healthy_avg['thalch'], healthy_avg['trestbps']]
        
        ax.bar(x - width, user_vals, width, label='Bu Hasta', color='#3498db')
        ax.bar(x, sick_vals, width, label='Ortalama Riskli Hasta', color='#e74c3c')
        ax.bar(x + width, healthy_vals, width, label='Ortalama SaÄŸlÄ±klÄ± Hasta', color='#2ecc71')
        
        ax.set_ylabel('DeÄŸerler')
        ax.set_title('Hasta Metrikleri vs Genel PopÃ¼lasyon')
        ax.set_xticks(x)
        ax.set_xticklabels(labels_compare)
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        
        st.pyplot(fig)

        # Ã–zellik Ã–nemi
        st.subheader("Model Karar FaktÃ¶rleri")
        st.markdown("AÅŸaÄŸÄ±daki Ã¶zellikler modelin tahminini en Ã§ok etkileyen faktÃ¶rlerdir:")
        
        fig_imp, ax_imp = plt.subplots(figsize=(11, 6))
        top_features = feature_importance.head(10)
        colors = plt.cm.RdYlGn_r(np.linspace(0.3, 0.7, len(top_features)))
        ax_imp.barh(range(len(top_features)), top_features['importance'], color=colors)
        ax_imp.set_yticks(range(len(top_features)))
        ax_imp.set_yticklabels(top_features['feature'])
        ax_imp.set_xlabel('Ã–nem Skoru')
        ax_imp.set_title('En Ã–nemli 10 Karar FaktÃ¶rÃ¼')
        ax_imp.invert_yaxis()
        
        st.pyplot(fig_imp)

        # Yasal UyarÄ±
        st.error("""
        âš ï¸ **TIBBÄ° SORUMLULUK REDDÄ°**
        
        Bu uygulama **yalnÄ±zca tahmin aracÄ±dÄ±r** ve tÄ±bbi teÅŸhis cihazÄ± DEÄÄ°LDÄ°R.
        SonuÃ§lar yalnÄ±zca bilgilendirme amaÃ§lÄ±dÄ±r. 
        
        **TÄ±bbi Ã¶neri, teÅŸhis ve tedavi iÃ§in MUTLAKA uzman bir saÄŸlÄ±k kuruluÅŸuna baÅŸvurunuz.**
        """)

with col2:
    st.info("ğŸ“Š **Model Bilgileri**")
    st.markdown(f"""
    **Performans Metrikleri:**
    - Test DoÄŸruluÄŸu: {model_info['accuracy']:.2%}
    - ROC-AUC: {model_info['roc_auc']:.4f}
    - Ã‡apraz DoÄŸrulama Skoru: {model_info['cv_mean']:.4f} Â± {model_info['cv_std']:.4f}
    
    **Veri Seti Bilgisi:**
    - Ã–rnekler: {len(df_clean)}
    - Risk SÄ±nÄ±fÄ±: %{model_info['positive_class_pct']:.1f}
    - Test Seti: {model_info['test_set_size']} hasta
    
    **Model Ã–zellikleri:**
    - Topluluk Modeli (RF + GB + LR)
    - Hiperparametre AyarlamalÄ±
    - SÄ±nÄ±f AÄŸÄ±rlÄ±ÄŸÄ± DengelenmiÅŸ
    - Ã‡apraz DoÄŸrulanmÄ±ÅŸ
    
    **GiriÅŸ Parametreleri:**
    - **cp:** GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± tipi
    - **trestbps:** Ä°stirahat kan basÄ±ncÄ±
    - **chol:** Kolesterol
    - **thalch:** Maksimum kalp hÄ±zÄ±
    - **oldpeak:** ST depresyonu
    - **ca:** Ana damar sayÄ±sÄ±
    - **thal:** Talasemi durumu
    """)
    
    # Model karÅŸÄ±laÅŸtÄ±rma bilgisi
    st.info("**Model HakkÄ±nda:**\n\nBu uygulama optimize edilmiÅŸ topluluk modeli kullanÄ±r:\n- Rastgele Orman (RF)\n- Gradyan ArttÄ±rma (GB)\n- Lojistik Regresyon (LR)")
    
    # Analiz gÃ¶rsellerini gÃ¶ster
    import os
    
    if os.path.exists('results/feature_importance.png'):
        st.markdown("---")
        st.subheader("Ã–zellik Ã–nem Analizi")
        st.image('results/feature_importance.png', caption='Model Analiz Raporu: Ã–zellik Ã–nemi', use_container_width=True)
    
    if os.path.exists('results/model_comparison.png'):
        st.markdown("---")
        st.subheader("Model KarÅŸÄ±laÅŸtÄ±rma")
        st.image('results/model_comparison.png', caption='Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±', use_container_width=True)
